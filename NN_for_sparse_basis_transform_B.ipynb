{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn4iAkRUg8BA"
      },
      "source": [
        "# Neural Network for sparse basis transformation B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyWe7skNhWn6"
      },
      "source": [
        "## Definitions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzwck_fxinjh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib as mpl\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageSequence\n",
        "time = datetime.now()\n",
        "!mkdir plots\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "torch.manual_seed(12345)\n",
        "np.random.seed(12345)\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# -------------------------- Fully Connected Network --------------------------\n",
        "# ----------------------------------------------------------------------------- \n",
        "class FCN(nn.Module): \n",
        "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "        super().__init__()\n",
        "        activation = nn.Tanh #Specify the used activation function\n",
        "        self.fc1 = nn.Sequential(*[nn.Linear(N_INPUT, N_HIDDEN), activation()]) #Input to first hidden layer\n",
        "        self.fc2 = nn.Sequential(*[nn.Sequential(*[nn.Linear(N_HIDDEN, N_HIDDEN), activation()]) for _ in range(N_LAYERS-1)]) #Going through the remaining hidden layers\n",
        "        self.fc3 = nn.Linear(N_HIDDEN, N_OUTPUT) #Last hidden layer to output layer\n",
        "\n",
        "    def forward(self, *args):\n",
        "        if len(args) == 1: #When multiple initial conditions are specified, this will provide the correct shape. \n",
        "            x = args[0]\n",
        "        elif len(np.shape(args[0])) <= 1:\n",
        "            x = torch.FloatTensor([*args]).T\n",
        "        else:\n",
        "            x = torch.FloatTensor(torch.cat([*args], 1))\n",
        "\n",
        "        x = self.fc1(x) #Going through the layers\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# ----------------------------------------------------------------------------- \n",
        "# -------------------------- Creating GIF animations -------------------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "def save_gif(outfile, files, fps=5, loop=0):\n",
        "    imgs = [Image.open(file) for file in files]\n",
        "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)\n",
        "\n",
        "def split(array, nrows, ncols):\n",
        "    r, h = array.shape\n",
        "    return (array.reshape(h//nrows, nrows, -1, ncols)\n",
        "                 .swapaxes(1, 2)\n",
        "                 .reshape(-1, nrows, ncols))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 1: Load uploaded image"
      ],
      "metadata": {
        "id": "-9XPKBz1SuVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "img_files = ['amyloid64.png','checker64.png','zehner64.png','astrocyte64.png']\n",
        "for img_file in img_files:\n",
        "    im = Image.open(img_file)\n",
        "    im = im.convert('L')\n",
        "    A = []\n",
        "    for image in ImageSequence.Iterator(im):\n",
        "        A.append(np.array(image).flatten())\n",
        "    A = np.row_stack(A)\n",
        "    input = (A-np.min(A))/(np.max(A)-np.min(A))\n",
        "    input = input[0]\n",
        "    pixelsize = int(np.sqrt(len(input)))\n",
        "    fig = plt.figure(figsize=(20,15))\n",
        "    ax = fig.add_subplot(151)\n",
        "    ax.title.set_text('$x$')\n",
        "    ax.imshow(input.reshape(pixelsize,pixelsize), interpolation='none', cmap=cm.Greys_r, vmin=0, vmax=1)\n",
        "    images.append(input)"
      ],
      "metadata": {
        "id": "OwaVbkbKBfui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 2: Load CIFAR10 images"
      ],
      "metadata": {
        "id": "mZ7xWPzfTuUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 300\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img/2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
        "\n",
        "imgs = torchvision.transforms.functional.rgb_to_grayscale(images)\n",
        "A = []\n",
        "for image in imgs:\n",
        "    A.append(np.array(image).flatten())\n",
        "A = np.row_stack(A)\n",
        "images = (A-np.min(A))/(np.max(A)-np.min(A))\n",
        "pixelsize = int(np.sqrt(len(images[0])))"
      ],
      "metadata": {
        "id": "QYcSRHMB3vHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the network"
      ],
      "metadata": {
        "id": "JPZG1EsO7tGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------- \n",
        "# ------------------------------- NN parameters ------------------------------- \n",
        "# ----------------------------------------------------------------------------- \n",
        "lr = 1e-1                     #Learning rate\n",
        "INPUT = pixelsize**2          #Amount of input values\n",
        "N_HIDDEN = 16                 #Amount of neurons in hidden layers\n",
        "N_LAYERS = 3                  #Amount of hidden layers\n",
        "OUTPUT = pixelsize**2         #Amount of output values\n",
        "epsilon = 10e-8               #Threshold to approximate L0 norm\n",
        "im_number = 250               #Amount of images used\n",
        "image_iterations = 250        #Amount of iterations executed per image\n",
        "\n",
        "time = datetime.now()         #Keep track of time\n",
        "\n",
        "model1 = FCN(INPUT,OUTPUT,N_HIDDEN,N_LAYERS) #Create a network for C\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(),lr=lr)   #Adam optimizer\n",
        "model2 = FCN(INPUT,OUTPUT,N_HIDDEN,N_LAYERS) #Create a network for D\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(),lr=lr)   #Adam optimizer\n",
        "\n",
        "files = []\n",
        "counter = 0\n",
        "for i in range(1,int(image_iterations*im_number)):\n",
        "    if i%image_iterations == 0:\n",
        "        counter += 1\n",
        "    input = images[counter]\n",
        "\n",
        "    optimizer1.zero_grad()\n",
        "    optimizer2.zero_grad()\n",
        "    C = torch.reshape(model1(torch.Tensor(input)), (pixelsize,pixelsize)) \n",
        "    D = torch.reshape(model2(torch.Tensor(input)), (pixelsize,pixelsize))\n",
        "    B = torch.kron(C, D)\n",
        "    bx = torch.linalg.solve(B, torch.Tensor(input)) # Solve B(B_inv x)=x for 'B_inv x'\n",
        "    \n",
        "    loss_sparse = sum(torch.sqrt((bx)**2 + epsilon))\n",
        "    loss_orth_C = (10e5)*torch.mean((torch.matmul(C, torch.t(C)) - torch.Tensor(np.identity(pixelsize)))**2)\n",
        "    loss_orth_D = (10e5)*torch.mean((torch.matmul(D, torch.t(D)) - torch.Tensor(np.identity(pixelsize)))**2)\n",
        "    loss = loss_sparse + loss_orth_C + loss_orth_D\n",
        "\n",
        "    loss.backward()\n",
        "    def closure(): return loss\n",
        "    optimizer1.step(closure)\n",
        "    optimizer2.step(closure)\n",
        "    loss = loss.detach()\n",
        "\n",
        "    # Adaptive learning rate \n",
        "    if i%(image_iterations//2) == 0:\n",
        "        lr = 10e-3 # Decrease when half of iterations passed per image\n",
        "    if i%image_iterations == 0:\n",
        "        lr = 10e-1 # Reset to larger lr\n",
        "\n",
        "    if i%50 == 0:\n",
        "        C = C.detach().numpy()\n",
        "        D = D.detach().numpy()\n",
        "        C_inv = np.linalg.inv(C)\n",
        "        D_inv = np.linalg.inv(D)\n",
        "        B = np.kron(C,D)\n",
        "        B_inv = np.kron(C_inv,D_inv)\n",
        "\n",
        "        threshold = 1e-15\n",
        "        sparsity1 = (input < threshold).sum()\n",
        "        sparsity2 = (np.matmul(B_inv, input) < threshold).sum()\n",
        "        print('Sparsity before:', sparsity1)\n",
        "        print('Sparsity after:', sparsity2)\n",
        "\n",
        "        fig = plt.figure(figsize=(20,15))\n",
        "        ax1 = fig.add_subplot(141)\n",
        "        ax1.title.set_text('$x$')\n",
        "        ax1.imshow(input.reshape(pixelsize,pixelsize), interpolation='none', cmap=cm.Greys_r, vmin=0, vmax=1)\n",
        "        ax2 = fig.add_subplot(142)\n",
        "        ax2.title.set_text('$B^{-1}$')\n",
        "        ax2.imshow(B_inv, interpolation='none', cmap=cm.Greys_r, vmin=0, vmax=1)\n",
        "        ax3 = fig.add_subplot(143)\n",
        "        ax3.title.set_text('$BB^{T}x$')\n",
        "        ax3.imshow(np.matmul(np.matmul(B, B.transpose()), input).reshape(pixelsize,pixelsize), interpolation='none', cmap=cm.Greys_r, vmin=0, vmax=1)\n",
        "        ax4 = fig.add_subplot(144)\n",
        "        ax4.title.set_text('$B^{-1}x$')\n",
        "        ax4.imshow(np.matmul(B_inv, input).reshape(pixelsize,pixelsize), interpolation='none', cmap=cm.Greys_r, vmin=0, vmax=1)\n",
        "        \n",
        "        file = \"plots/nn_%.8i.png\"%(i)\n",
        "        plt.annotate(\"Iteration: %i\"%(i),xy=(1.05, 0.87),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "        plt.annotate(\"Sparsity $x$: %i\"%(sparsity1),xy=(1.05, 0.77),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "        plt.annotate(\"Sparsity $B^{-1}x$: %i\"%(sparsity2),xy=(1.05, 0.67),xycoords='axes fraction',fontsize=\"x-large\",color=\"k\")\n",
        "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "        files.append(file)\n",
        "        plt.show()\n",
        "        print(i, datetime.now() - time, loss_sparse, loss_orth_C, loss_orth_D)\n",
        "\n",
        "save_gif(\"nn.gif\", files, fps=20, loop=0)\n",
        "\n",
        "B = B.detach().numpy().reshape(INPUT,INPUT)\n",
        "print('error',np.mean((np.matmul(B,np.matmul(np.linalg.inv(B),input))-input)**2))\n",
        "np.savetxt(\"B.csv\", B, delimiter=\",\")\n",
        "print('Sparsity before:', (input < 1e-10).sum())\n",
        "print('Sparsity after:', (np.matmul(B, input) < 1e-10).sum())"
      ],
      "metadata": {
        "id": "BvaL_vEJfXHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtaining samples for GPSR"
      ],
      "metadata": {
        "id": "ytjQDneN7pTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain 5 training data samples\n",
        "for i in range(5):\n",
        "    index = np.random.randint(im_number)\n",
        "    I = images[index].reshape(pixelsize,pixelsize)\n",
        "    I8 = (((I-I.min())/(I.max()-I.min()))*255.9).astype(np.uint8)\n",
        "    img = Image.fromarray(I8)\n",
        "    img.save(f\"img{index}.png\")\n",
        "#Obtain 5 test data samples\n",
        "for i in range(5):\n",
        "    index = np.random.randint(im_number,batch_size)\n",
        "    I = images[index].reshape(pixelsize,pixelsize)\n",
        "    I8 = (((I-I.min())/(I.max()-I.min()))*255.9).astype(np.uint8)\n",
        "    img = Image.fromarray(I8)\n",
        "    img.save(f\"img{index}.png\")"
      ],
      "metadata": {
        "id": "TyyBPk-VzdYi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}